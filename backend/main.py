import asyncpg
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from typing import List
from fpdf import FPDF
import io
import datetime
import zipfile
import re # NEW: For Deep Scanning
import secrets # NEW: For Cryptographic Salt

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- CONFIGURATION ---
# 1. Metadata Keywords (The "Quick Look")
PII_KEYWORDS = ['name', 'email', 'ssn', 'social', 'phone', 'mobile', 'addr', 'city', 'zip', 'card', 'credit']
SAFE_KEYWORDS = ['id', 'date', 'time', 'amount', 'balance', 'price', 'merchant', 'status', 'code', 'type', 'sku']

# 2. Deep Content Regex (The "Deep Look")
REGEX_PATTERNS = {
    'EMAIL': r'^[\w\.-]+@[\w\.-]+\.\w+$',
    'PHONE': r'^\+?1?\d{9,15}$',
    'CREDIT_CARD': r'^\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}$',
    'SSN': r'^\d{3}-?\d{2}-?\d{4}$'
}

AEGIS_DB_DSN = "postgresql://postgres:root@localhost:5432/aegisdb"

# --- MODELS ---
class ConnectionDetails(BaseModel):
    db_name: str
    user: str
    password: str
    host: str = "localhost"
    port: str = "5432"

class BulkSearchRequest(BaseModel):
    connection: ConnectionDetails
    table_name: str
    primary_key_col: str
    target_ids: List[str]

class BulkErasureRequest(BaseModel):
    connection: ConnectionDetails
    target_table: str
    target_id_col: str
    target_ids: List[str]
    columns_to_clean: List[dict] 

def build_dsn(c: ConnectionDetails):
    return f"postgresql://{c.user}:{c.password}@{c.host}:{c.port}/{c.db_name}"

# --- HELPER: PRO PDF GENERATOR ---
def create_certificate(db_name, table_name, record_id, original_data, columns_cleaned, timestamp, salt):
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.rect(5, 5, 200, 287, 'D')
        
        pdf.set_font("Times", 'B', 24)
        pdf.cell(190, 20, txt="CERTIFICATE OF ERASURE", ln=1, align='C')
        
        pdf.set_font("Arial", 'I', 10)
        pdf.cell(190, 5, txt="Generated by Aegis Sovereignty Engine v2.6 (Secure Core)", ln=1, align='C')
        pdf.line(20, 35, 190, 35)
        pdf.ln(15)
        
        pdf.set_font("Arial", 'B', 12)
        pdf.cell(190, 10, txt="EXECUTION METADATA", ln=1, align='L')
        pdf.set_font("Arial", size=11)
        
        def add_row(label, value):
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(50, 8, txt=label, border=1)
            pdf.set_font("Arial", size=11)
            pdf.cell(140, 8, txt=str(value), border=1, ln=1)

        add_row("Execution Timestamp", timestamp)
        add_row("Target Database", db_name)
        add_row("Target Table", table_name)
        add_row("Record ID", str(record_id))
        # NEW: Document the Salt on the certificate for audit verification
        add_row("Cryptographic Salt", salt) 
        
        pdf.ln(10)

        pdf.set_font("Arial", 'B', 12)
        pdf.cell(190, 10, txt="PRE-ERASURE SNAPSHOT", ln=1, align='L')
        pdf.set_font("Courier", size=10) 
        
        for col in columns_cleaned:
            c_name = str(col['col'])
            val = str(original_data.get(c_name, 'NULL')).encode('latin-1', 'replace').decode('latin-1')
            pdf.cell(60, 6, txt=c_name, border=1)
            pdf.cell(130, 6, txt=val, border=1, ln=1)

        pdf.ln(10)
        pdf.set_font("Times", '', 12)
        pdf.multi_cell(190, 6, txt="This document certifies that PII has been irreversibly pseudonymized using Salted Hashing. The original values are no longer stored in the active database.")
        
        output = pdf.output(dest='S')
        if isinstance(output, str): return output.encode('latin-1', 'replace')
        return output
    except Exception as e:
        print(f"[DEBUG] PDF Error: {e}")
        return b"Error"

# --- ENDPOINTS ---

@app.post("/scan-target")
async def scan_target_database(conn_details: ConnectionDetails):
    dsn = build_dsn(conn_details)
    try:
        conn = await asyncpg.connect(dsn)
        try:
            # 1. Get Metadata
            query_cols = "SELECT table_name, column_name, data_type FROM information_schema.columns WHERE table_schema = 'public' ORDER BY table_name, ordinal_position;"
            rows = await conn.fetch(query_cols)
            
            # 2. Get PKs
            query_pk = """
                SELECT kcu.table_name, kcu.column_name
                FROM information_schema.table_constraints tco
                JOIN information_schema.key_column_usage kcu 
                  ON kcu.constraint_name = tco.constraint_name
                  AND kcu.table_schema = tco.table_schema
                WHERE tco.constraint_type = 'PRIMARY KEY';
            """
            pk_rows = await conn.fetch(query_pk)
            pk_map = {r['table_name']: r['column_name'] for r in pk_rows}

            schema_map = {}
            
            # 3. ANALYZE EACH COLUMN
            for r in rows:
                tbl = r['table_name']
                col = r['column_name'].lower()
                dtype = r['data_type']
                
                strategy = "IGNORE"
                reason = "Default"

                # LEVEL 1: KEYWORD SEARCH (Fast)
                if any(k in col for k in SAFE_KEYWORDS): 
                    strategy = "PRESERVE"
                    reason = "Safe Keyword Match"
                elif any(k in col for k in PII_KEYWORDS) and dtype in ['text', 'character varying']: 
                    strategy = "HASH"
                    reason = "PII Keyword Match"
                
                # LEVEL 2: DEEP SCAN (Slow but Smart)
                # If strategy is still IGNORE and it's a text column, look at the data!
                if strategy == "IGNORE" and dtype in ['text', 'character varying']:
                    try:
                        # Fetch 5 non-null values to test
                        sample_q = f"SELECT {r['column_name']} FROM {tbl} WHERE {r['column_name']} IS NOT NULL LIMIT 5"
                        samples = await conn.fetch(sample_q)
                        
                        for s_row in samples:
                            val = str(s_row[0])
                            for p_name, p_regex in REGEX_PATTERNS.items():
                                if re.match(p_regex, val):
                                    strategy = "HASH"
                                    reason = f"Detected {p_name} Pattern"
                                    break
                            if strategy == "HASH": break
                    except:
                        pass # If scan fails, skip deep scan

                if tbl not in schema_map: 
                    schema_map[tbl] = {
                        "primary_key": pk_map.get(tbl, "UNKNOWN"), 
                        "columns": []
                    }
                
                schema_map[tbl]["columns"].append({
                    "name": r['column_name'], 
                    "type": dtype, 
                    "suggested_strategy": strategy,
                    "reason": reason # Send reason to Frontend
                })
                
            return {"status": "connected", "schema": schema_map}
        finally:
            await conn.close()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Connection Failed: {str(e)}")

@app.post("/fetch-batch-details")
async def fetch_batch_details(req: BulkSearchRequest):
    dsn = build_dsn(req.connection)
    try:
        conn = await asyncpg.connect(dsn)
        try:
            query = f"SELECT * FROM {req.table_name} WHERE {req.primary_key_col}::text = ANY($1::text[])"
            rows = await conn.fetch(query, req.target_ids)
            results = []
            for row in rows:
                data = dict(row)
                for k, v in data.items(): data[k] = str(v)
                results.append(data)
            return results
        finally:
            await conn.close()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/execute-erasure")
async def execute_erasure(req: BulkErasureRequest):
    print(f"[DEBUG] Processing {len(req.target_ids)} records...")
    timestamp = str(datetime.datetime.now())
    clean_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # NEW: Generate a Cryptographic Salt (Random String)
    # This prevents Rainbow Table attacks.
    session_salt = secrets.token_hex(8) 

    try:
        target_dsn = build_dsn(req.connection)
        conn = await asyncpg.connect(target_dsn)
        aegis_conn = await asyncpg.connect(AEGIS_DB_DSN)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB Connection Error: {e}")

    single_pdf_bytes = None

    try:
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
            
            for target_id in req.target_ids:
                try:
                    fetch_q = f"SELECT * FROM {req.target_table} WHERE {req.target_id_col}::text = $1"
                    row = await conn.fetchrow(fetch_q, str(target_id))
                    if not row: continue
                    original_data = dict(row)

                    async with conn.transaction():
                        for col_rule in req.columns_to_clean:
                            col = col_rule['col']
                            # NEW: Salted Hash Logic
                            # md5(salt + value)
                            sql = f"UPDATE {req.target_table} SET {col} = 'HASH_' || md5('{session_salt}' || {col}::text) WHERE {req.target_id_col}::text = $1"
                            await conn.execute(sql, str(target_id))

                    cols_str = ", ".join([c['col'] for c in req.columns_to_clean])
                    
                    try: pk_int = int(target_id)
                    except: pk_int = 0
                        
                    await aegis_conn.execute("""
                        INSERT INTO audit_logs (target_db, target_table, target_pk_id, columns_cleaned, status)
                        VALUES ($1, $2, $3, $4, 'SUCCESS')
                    """, req.connection.db_name, req.target_table, pk_int, cols_str)

                    # Pass Salt to Certificate
                    pdf_bytes = create_certificate(req.connection.db_name, req.target_table, target_id, original_data, req.columns_to_clean, timestamp, session_salt)
                    
                    if len(req.target_ids) == 1:
                        single_pdf_bytes = pdf_bytes
                    else:
                        zip_file.writestr(f"Certificate_{target_id}.pdf", pdf_bytes)

                except Exception as e:
                    print(f"Error on ID {target_id}: {e}")
                    continue

    finally:
        await conn.close()
        await aegis_conn.close()

    if len(req.target_ids) == 1 and single_pdf_bytes:
        return StreamingResponse(
            io.BytesIO(single_pdf_bytes),
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename=Certificate_{req.target_ids[0]}.pdf"}
        )
    else:
        zip_buffer.seek(0)
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip", 
            headers={"Content-Disposition": f"attachment; filename=AEGIS_Batch_{clean_time}.zip"}
        )