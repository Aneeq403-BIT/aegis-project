import asyncpg
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Any
from fpdf import FPDF
import io
import datetime
import zipfile

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- CONFIGURATION ---
PII_KEYWORDS = ['name', 'email', 'ssn', 'social', 'phone', 'mobile', 'addr', 'city', 'zip']
SAFE_KEYWORDS = ['id', 'date', 'time', 'amount', 'balance', 'price', 'merchant', 'status', 'code', 'type']
AEGIS_DB_DSN = "postgresql://postgres:root@localhost:5432/aegisdb"

# --- MODELS ---
class ConnectionDetails(BaseModel):
    db_name: str
    user: str
    password: str
    host: str = "localhost"
    port: str = "5432"

class BulkSearchRequest(BaseModel):
    connection: ConnectionDetails
    table_name: str
    primary_key_col: str
    target_ids: List[int]

class BulkErasureRequest(BaseModel):
    connection: ConnectionDetails
    target_table: str
    target_id_col: str
    target_ids: List[int]
    columns_to_clean: List[dict] 

def build_dsn(c: ConnectionDetails):
    return f"postgresql://{c.user}:{c.password}@{c.host}:{c.port}/{c.db_name}"

# --- HELPER: PDF GENERATOR ---
def create_certificate(db_name, table_name, record_id, original_data, columns_cleaned, timestamp):
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        pdf.set_font("Arial", 'B', 16)
        pdf.cell(200, 10, txt="CERTIFICATE OF ERASURE", ln=1, align='C')
        pdf.ln(10)
        pdf.set_font("Arial", size=12)
        pdf.cell(200, 10, txt=f"Date of Execution: {timestamp}", ln=1)
        pdf.cell(200, 10, txt=f"Target Database: {db_name}", ln=1)
        pdf.cell(200, 10, txt=f"Table Affected: {table_name}", ln=1)
        pdf.cell(200, 10, txt=f"Record ID: {record_id}", ln=1)
        pdf.ln(10)
        pdf.set_font("Arial", 'B', 12)
        pdf.cell(200, 10, txt="Original Data Snapshot:", ln=1)
        pdf.set_font("Arial", size=10)
        for col in columns_cleaned:
            c_name = str(col['col'])
            val = str(original_data.get(c_name, 'N/A')).encode('latin-1', 'replace').decode('latin-1')
            pdf.cell(200, 8, txt=f"- {c_name}: {val}", ln=1)
        pdf.ln(10)
        pdf.set_font("Arial", 'I', 10)
        pdf.cell(200, 10, txt="Generated by Aegis Sovereignty Engine v2.5", ln=1, align='C')
        output = pdf.output(dest='S')
        if isinstance(output, str): return output.encode('latin-1', 'replace')
        return output
    except Exception as e:
        print(f"[DEBUG] PDF Error: {e}")
        return b"Error"

# --- ENDPOINTS ---

@app.post("/scan-target")
async def scan_target_database(conn_details: ConnectionDetails):
    dsn = build_dsn(conn_details)
    try:
        conn = await asyncpg.connect(dsn)
        try:
            query = "SELECT table_name, column_name, data_type FROM information_schema.columns WHERE table_schema = 'public' ORDER BY table_name, ordinal_position;"
            rows = await conn.fetch(query)
            schema_map = {}
            for r in rows:
                tbl = r['table_name']
                col = r['column_name'].lower()
                dtype = r['data_type']
                strategy = "IGNORE"
                if any(k in col for k in SAFE_KEYWORDS): strategy = "PRESERVE"
                elif any(k in col for k in PII_KEYWORDS) and dtype in ['text', 'character varying']: strategy = "HASH"
                if tbl not in schema_map: schema_map[tbl] = []
                schema_map[tbl].append({"name": r['column_name'], "type": dtype, "suggested_strategy": strategy})
            return {"status": "connected", "schema": schema_map}
        finally:
            await conn.close()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Connection Failed: {str(e)}")

# --- NEW ENDPOINT: FETCH BATCH DETAILS (For Preview) ---
@app.post("/fetch-batch-details")
async def fetch_batch_details(req: BulkSearchRequest):
    dsn = build_dsn(req.connection)
    try:
        conn = await asyncpg.connect(dsn)
        try:
            # Use ANY($1) for array of IDs
            query = f"SELECT * FROM {req.table_name} WHERE {req.primary_key_col} = ANY($1::int[])"
            rows = await conn.fetch(query, req.target_ids)
            
            results = []
            for row in rows:
                data = dict(row)
                for k, v in data.items(): data[k] = str(v)
                results.append(data)
                
            return results
        finally:
            await conn.close()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/execute-erasure")
async def execute_erasure(req: BulkErasureRequest):
    print(f"[DEBUG] Processing {len(req.target_ids)} records...")
    timestamp = str(datetime.datetime.now())
    clean_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S") # Unique ID for file

    try:
        target_dsn = build_dsn(req.connection)
        conn = await asyncpg.connect(target_dsn)
        aegis_conn = await asyncpg.connect(AEGIS_DB_DSN)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"DB Connection Error: {e}")

    # HOLDER FOR SINGLE PDF (If count == 1)
    single_pdf_bytes = None

    try:
        # PREPARE ZIP BUFFER
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
            
            for target_id in req.target_ids:
                try:
                    # 1. Fetch
                    fetch_q = f"SELECT * FROM {req.target_table} WHERE {req.target_id_col} = $1"
                    row = await conn.fetchrow(fetch_q, target_id)
                    if not row: continue
                    original_data = dict(row)

                    # 2. Update
                    async with conn.transaction():
                        for col_rule in req.columns_to_clean:
                            col = col_rule['col']
                            sql = f"UPDATE {req.target_table} SET {col} = 'HASH_' || md5({col}::text) WHERE {req.target_id_col} = $1"
                            await conn.execute(sql, target_id)

                    # 3. Log
                    cols_str = ", ".join([c['col'] for c in req.columns_to_clean])
                    await aegis_conn.execute("""
                        INSERT INTO audit_logs (target_db, target_table, target_pk_id, columns_cleaned, status)
                        VALUES ($1, $2, $3, $4, 'SUCCESS')
                    """, req.connection.db_name, req.target_table, target_id, cols_str)

                    # 4. Generate PDF
                    pdf_bytes = create_certificate(req.connection.db_name, req.target_table, target_id, original_data, req.columns_to_clean, timestamp)
                    
                    if len(req.target_ids) == 1:
                        single_pdf_bytes = pdf_bytes # Save for single return
                    else:
                        zip_file.writestr(f"Certificate_{target_id}.pdf", pdf_bytes)

                except Exception as e:
                    print(f"Error on ID {target_id}: {e}")
                    continue

    finally:
        await conn.close()
        await aegis_conn.close()

    # DECISION: ZIP OR PDF?
    if len(req.target_ids) == 1 and single_pdf_bytes:
        # Return Single PDF
        return StreamingResponse(
            io.BytesIO(single_pdf_bytes),
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename=Certificate_ID_{req.target_ids[0]}_{clean_time}.pdf"}
        )
    else:
        # Return ZIP
        zip_buffer.seek(0)
        return StreamingResponse(
            zip_buffer, 
            media_type="application/zip", 
            headers={"Content-Disposition": f"attachment; filename=AEGIS_Batch_{clean_time}.zip"}
        )